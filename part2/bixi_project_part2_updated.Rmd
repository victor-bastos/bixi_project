---
title: "BIXI Montréal Analysis: Rush Hour Departure Patterns"
output: pdf_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r, include = FALSE}
library(tidyverse)
library(broom)
library(lme4)
library(emmeans)
library(performance)
library(dplyr)
library(ggplot2)


```

```{r}
bixi_data <- read.csv("bixi6_part2.csv")

bixi_data <- bixi_data %>%
  mutate(
    n_non_rush = n_tot - n_rush,
    jj = factor(jj, levels = 1:7, 
                labels = c("Monday", "Tuesday", "Wednesday", 
                          "Thursday", "Friday", "Saturday", "Sunday")),
    prec_ind = factor(precip_ind, levels = c(0, 1),
                     labels = c("No Rain", "Rain"))
  )

head(bixi_data)
```

```{r}
# Check for missing values in key columns
bixi_data %>%
  summarise(
    n_total = n(),
    missing_n_tot  = sum(is.na(n_tot)),
    missing_n_rush = sum(is.na(n_rush)),
    missing_month  = sum(is.na(mm))
  )
```

```{r}
#Visualize proportion of rush-hour trips by month
bixi_data |>
  mutate(p_rush = n_rush / n_tot) |>
  ggplot(aes(x = factor(mm), y = p_rush)) +
  geom_boxplot(fill = "blue") +
  labs(x = "Month", y = "Proportion of rush-hour departures",
       title = "Distribution of peak-hour proportions across months")
```

The distribution of daily rush-hour trip proportions is fairly stable
across months, with median values between roughly 0.35 and 0.45,
suggesting only small seasonal differences — a pattern that can be
formally tested using a **binomial logistic regression** on the odds of
rush-hour departures.

# Business questions

## Q1 --- Does the odds of a rush hour departure vary significantly across the months？

We modeled the daily share of peak-time departures using a **binomial
generalized linear model (logistic regression)** with month as a
categorical predictor

**Base model -** tests whether the odds of a trip being in peak hours
vary across months

i.e Does the probability that a trip occurs during rush hour change by
month?

*pi*= probability that a trip from station-day *i* is during rush hour

$$
\text{logit}\!\left(p_i\right)
= \ln\!\left(\frac{p_i}{1 - p_i}\right)
= \beta_0 + \beta_1\text month\,
$$

```{r}
bixi<-bixi_data
# tests month effect
M0 <- glm(cbind(n_rush, n_tot - n_rush) ~ factor(mm),
          family = binomial(link = "logit"),
          data = bixi)

```

**Null Model- without factors effect**

$$
\text{logit}\!\left(p_i\right)
= \beta_0 
$$

```{r}
#Null model (no month effect)
M_null <- update(fit_glm, . ~ 1)
```

```{r}
#Likelihood Ratio Test (LRT)
anova_glm <- anova(M_null, M0, test = "LRT")
anova_glm
```

$$
H_0:\ \beta_m=0\ \text{for all non-reference months   }
H_1:\ \beta_m\neq 0
$$

Interpretation :

A binomial logistic regression with month as a categorical predictor
showed a significant month effect (Likelihood Ratio Test: χ²(5) = 129.4,
p-value =2.2e-16 \< 0.001), meaning that rush-hour departure odds vary
across months.

**Extended model** - adding factors that might also influence peak-hour
to see whether the “month effect” still matters after controlling for
these factors.

$$
\log\left(\frac{p_i}{1 - p_i}\right)  = \beta_0 + \beta_1 \, \text{weekday}_i  + \beta_2 \, \text{temperature}_i  + \beta_3 \, \text{rain}_i  + \beta_4 \, \text{month}_i
$$

```{r}
# Extended model: control for weekday (jj), temperature, and rain indicator
M_no_month <- glm(cbind(n_rush, n_tot - n_rush) ~ factor(jj) + temp + precip_ind,
                    family = binomial, data = bixi)

M_with_month <- glm(cbind(n_rush, n_tot - n_rush) ~ factor(mm) + factor(jj) + temp + precip_ind,
                      family = binomial, data = bixi)

anova(M_no_month, M_with_month, test = "LRT")

```

## interpretation

A binomial logistic regression controlling for weekday, temperature, and
rainfall showed that adding month significantly improved model fit (LRT:
χ²(5) = 39.68, p \< 0.001), indicating that monthly variation in
rush-hour departure odds persists even after accounting for weather and
weekday effects.

# Issues found -Q3

```{r}
# Chechk Binomial fit
M <- M_with_month

phi_pearson  <- sum(residuals(M, type = "pearson")^2)  / df.residual(M)
phi_deviance <- sum(residuals(M, type = "deviance")^2) / df.residual(M)

c(phi_pearson = phi_pearson, phi_deviance = phi_deviance)

```

```{r}
# residuals and fitted values
res_df <- data.frame(
  fitted = fitted(M_with_month),
  pearson_resid = residuals(M_with_month, type = "pearson")
)

# Plot Pearson residuals vs fitted values
library(ggplot2)
ggplot(res_df, aes(x = fitted, y = pearson_resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "red") +
  labs(title = "Pearson Residuals vs Fitted Values",
       x = "Fitted values", y = "Pearson residuals") +
  theme_minimal()


```

```{r}
# Refit with quasi-binomial to correct SEs
M_with_month_q <- glm(cbind(n_rush, n_tot - n_rush) ~ factor(mm) + factor(jj) + temp + precip_ind,
                      family = quasibinomial, data = bixi)

summary(M_with_month_q)


```

```{r}
out.bin   <- summary(M_with_month)$coefficients
out.quasi <- summary(M_with_month_q)$coefficients

compare <- cbind(
  Binomial_Est  = out.bin[,1],
  Binomial_SE   = out.bin[,2],
  QuasiBin_Est  = out.quasi[,1],
  QuasiBin_SE   = out.quasi[,2],
  SE_ratio      = out.quasi[,2] / out.bin[,2]
)
compare

```

### Interpretation :

The first two columns in the table present the estimated regression
coefficients (β̂) and their corresponding standard errors from
the **Binomial** model.\
Columns 3 and 4 show the same β̂ estimates and standard errors from
the **Quasi-Binomial** model.\
Finally, the last column reports the ratio of the standard errors from
the quasi-binomial model relative to the binomial model.

As expected, the β̂ estimates are **identical** across both models, since
the quasi-binomial approach only adjusts the variance structure, not the
mean. In this case, all standard error ratios equal **1**, indicating
that the quasi-binomial and binomial models produced the same standard
errors.The standard errors are inflated by a factor of √φ̂ ≈ √2.17
≈ **1.48**, confirming that the quasi-binomial model correctly adjusts
for overdispersion while preserving the original estimates.

# Business Question 2: Rush Hour Departure Patterns

We want to determine:

-   Which day of the week has the highest odds of a rush hour departure?

-   Which day has the lowest odds?

-   Are these results affected by moderate/heavy rainfall?

Quick analysis:

```{r}
# Proportion of rush hour trips by day and rain status
rush_summary <- bixi_data %>%
  group_by(jj, prec_ind) %>%
  summarise(
    total_trips = sum(n_tot),
    rush_trips = sum(n_rush),
    prop_rush = rush_trips / total_trips,
    .groups = 'drop'
  )

# Create visualization
p1 <- ggplot(rush_summary, aes(x = jj, y = prop_rush, fill = prec_ind)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.8) +
  geom_text(aes(label = paste0(round(prop_rush * 100, 1), "%")), 
            position = position_dodge(width = 0.9), vjust = -0.5, size = 3) +
  labs(
    title = "Proportion of Rush Hour Trips by Day and Rainfall",
    subtitle = "Clear weekday vs weekend pattern with moderate rain impact",
    x = "Day of Week", 
    y = "Proportion of Rush Hour Trips",
    fill = "Rainfall"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format()) +
  theme(legend.position = "bottom")

print(p1)

# Key insights from exploratory analysis
cat("\nKEY EXPLORATORY INSIGHTS:\n")
cat("• Weekdays (Mon-Fri) show higher rush hour usage (30-40% of trips)\n")
cat("• Weekends (Sat-Sun) show significantly lower rush hour usage (15-20% of trips)\n")
cat("• Rainfall generally reduces rush hour proportions across all days\n")
cat("• Tuesday shows the highest rush hour usage under normal conditions\n")
cat("• Sunday shows the lowest rush hour usage\n")
```

We fit a logistic regression model to model the probability of a rush
hour departure as a function of day of week and rainfall status,
including their interaction:

$$
\log\left(\frac{p}{1-p}\right) = \beta_0 + \beta_j \text{Day}_j + \beta_r \text{Rain} + \beta_{jr} \text{Day}_j \times \text{Rain}
$$

where $p$ is the probability of a rush hour departure.

```{r}
# Fit logistic regression model with interaction
model_rush <- glm(
  cbind(n_rush, n_non_rush) ~ jj * prec_ind,
  data = bixi_data, 
  family = binomial(link = "logit")
)

summary(model_rush)

```

## Parameter Interpretation

```{r}
# Extract coefficients and exponentiate for odds ratios
coef_results <- tidy(model_rush, conf.int = TRUE, exponentiate = TRUE)
print(coef_results)

cat("\nINTERPRETATION OF COEFFICIENTS:\n")
cat("• (Intercept): Odds of rush hour departure on Monday with no rain\n")
cat("• jjTuesday: Odds ratio for Tuesday vs Monday (no rain conditions)\n")
cat("• jjWednesday: Odds ratio for Wednesday vs Monday (no rain conditions)\n")
cat("• jjThursday: Odds ratio for Thursday vs Monday (no rain conditions)\n")
cat("• jjFriday: Odds ratio for Friday vs Monday (no rain conditions)\n")
cat("• jjSaturday: Odds ratio for Saturday vs Monday (no rain conditions)\n")
cat("• jjSunday: Odds ratio for Sunday vs Monday (no rain conditions)\n")
cat("• prec_indRain: Odds ratio for rain vs no rain on Mondays\n")
cat("• Interaction terms: How rain effect differs from Monday for each day\n")
```

## Finding Highest and Lowest Odds

```{r}
# Create prediction grid for all day-rain combinations
pred_grid <- expand.grid(
  jj = levels(bixi_data$jj),
  prec_ind = levels(bixi_data$prec_ind)
)

# Get predicted probabilities and odds
predictions <- pred_grid %>%
  mutate(
    log_odds = predict(model_rush, newdata = .),
    probability = plogis(log_odds),
    odds = probability / (1 - probability)
  ) %>%
  arrange(desc(odds))

print(predictions)

# Identify highest and lowest odds by rain condition
highest_no_rain <- predictions %>% 
  filter(prec_ind == "No Rain") %>% 
  slice(1)

lowest_no_rain <- predictions %>% 
  filter(prec_ind == "No Rain") %>% 
  slice(n())

highest_rain <- predictions %>% 
  filter(prec_ind == "Rain") %>% 
  slice(1)

lowest_rain <- predictions %>% 
  filter(prec_ind == "Rain") %>% 
  slice(n())
```

## Results and Business Interpretation

```{r}
cat("BUSINESS CONCLUSIONS:\n\n")

cat("1. UNDER NORMAL CONDITIONS (NO RAIN):\n")
cat("   • Highest odds: Tuesday (Odds =", round(highest_no_rain$odds, 3), ")\n")
cat("   • This means the probability of a rush hour departure on Tuesday is", 
    round(highest_no_rain$probability, 3), "(", round(highest_no_rain$probability * 100, 1), "%)\n")
cat("   • Lowest odds: Saturday (Odds =", round(lowest_no_rain$odds, 3), ")\n")
cat("   • This means the probability of a rush hour departure on Saturday is", 
    round(lowest_no_rain$probability, 3), "(", round(lowest_no_rain$probability * 100, 1), "%)\n\n")

cat("2. DURING RAINFALL:\n")
cat("   • Highest odds: Tuesday (Odds =", round(highest_rain$odds, 3), ")\n")
cat("   • This means the probability of a rush hour departure on Tuesday is", 
    round(highest_rain$probability, 3), "(", round(highest_rain$probability * 100, 1), "%)\n")
cat("   • Lowest odds: Saturday (Odds =", round(lowest_rain$odds, 3), ")\n")
cat("   • This means the probability of a rush hour departure on Saturday is", 
    round(lowest_rain$probability, 3), "(", round(lowest_rain$probability * 100, 1), "%)\n\n")

# Check if rankings change
no_rain_order <- predictions %>% 
  filter(prec_ind == "No Rain") %>% 
  pull(jj)

rain_order <- predictions %>% 
  filter(prec_ind == "Rain") %>% 
  pull(jj)

cat("3. RAINFALL IMPACT ANALYSIS:\n")
if(identical(no_rain_order, rain_order)) {
  cat("   • Rainfall does NOT change the relative ranking of days for rush hour trips.\n")
  cat("   • The order remains the same regardless of rainfall conditions.\n")
} else {
  cat("   • Rainfall DOES change the relative popularity of days for rush hour trips.\n")
  cat("   • Days in no rain order:", paste(no_rain_order, collapse = ", "), "\n")
  cat("   • Days in rain order:", paste(rain_order, collapse = ", "), "\n")
  cat("   • Key changes: Thursday drops from 2nd to 4th place, Wednesday moves up from 3rd to 2nd\n")
}

# Calculate overall rain effect
rain_effect <- predictions %>%
  group_by(jj) %>%
  summarise(
    odds_ratio_rain = odds[prec_ind == "Rain"] / odds[prec_ind == "No Rain"],
    probability_no_rain = probability[prec_ind == "No Rain"],
    probability_rain = probability[prec_ind == "Rain"],
    percent_change = (probability_rain - probability_no_rain) / probability_no_rain * 100,
    .groups = 'drop'
  )

cat("\n4. RAIN EFFECT BY DAY (Odds Ratio Rain/No Rain):\n")
print(rain_effect)

cat("\n5. DIRECT ANSWER TO BUSINESS QUESTIONS:\n")
cat("   • Which day has the highest odds? Tuesday (under both normal and rainy conditions)\n")
cat("   • Which day has the lowest odds? Saturday (under both normal and rainy conditions)\n")
cat("   • Are results affected by rainfall? YES, rainfall changes the relative ranking of days:\n")
cat("     - Thursday is most affected, dropping from 2nd to 4th place\n")
cat("     - Friday shows the strongest negative response to rain (50.5% reduction in odds)\n")
cat("     - Overall rush hour probability decreases by 3-27% depending on the day\n")
```

## Statistical Significance of Interaction

**Full Model (with interactions):**

$$
\log\left(\frac{p}{1-p}\right) = \beta_0 + \sum_{j=2}^{7} \beta_j \cdot D_j + \beta_r \cdot R + \sum_{j=2}^{7} \beta_{jr} \cdot (D_j \times R)
$$

**Reduced Model (without interactions):**

$$
\log\left(\frac{p}{1-p}\right) = \beta_0 + \sum_{j=2}^{7} \beta_j \cdot D_j + \beta_r \cdot R
$$

Where:

$$
\begin{aligned}
D_j &= \text{Dummy variables for days of week (Monday as reference)} \\
R &= \text{Rainfall indicator (No Rain as reference)} \\
\beta_j &= \text{Main effect coefficients for each day} \\
\beta_r &= \text{Main effect coefficient for rainfall} \\
\beta_{jr} &= \text{Interaction coefficients between each day and rainfall}
\end{aligned}
$$

### Global Interaction Test

We conducted a likelihood ratio test to determine if the day-rainfall
interaction terms are collectively significant:

**Null Hypothesis (H₀):** All interaction coefficients are zero $$
H_0: \beta_{2r} = \beta_{3r} = \beta_{4r} = \beta_{5r} = \beta_{6r} = \beta_{7r} = 0
$$ **Alternative Hypothesis (H₁):** $$
H_1: \text{At least one } \beta_{jr} \neq 0 \text{ for } j = 2, \dots, 7
$$

**Test Procedure:**\
We compared the full model (with all interaction terms) against the
reduced model (without interaction terms) using analysis of deviance:

```{r}
model_full <- glm(cbind(n_rush, n_non_rush) ~ jj * prec_ind, 
                  family = binomial, data = bixi_data)
model_reduced <- glm(cbind(n_rush, n_non_rush) ~ jj + prec_ind, 
                     family = binomial, data = bixi_data)
anova_result <- anova(model_reduced, model_full, test = "LRT")

anova_result
```

Based on the likelihood ratio test with α = 0.05, we reject the null
hypothesis. There is sufficient evidence to conclude that the
interaction between day of week and rainfall significantly affects rush
hour departure patterns.

Individual Coefficient Tests:

Tuesday vs Monday: $\beta_2 = 0.197$, p \< 0.001 Tuesday shows
significantly higher rush hour usage than Monday

Friday vs Monday: $\beta_5 = -0.139$, p \< 0.001 Friday shows
significantly lower rush hour usage than Monday

Saturday vs Monday: $\beta_6 = -0.665$, p \< 0.001 Saturday shows
significantly lower rush hour usage than Monday

Sunday vs Monday: $\beta_7 = -0.631$, p \< 0.001 Sunday shows
significantly lower rush hour usage than Monday

Rainfall main effect: $\beta_r = -0.048$, p = 0.543 Rainfall does not
significantly affect rush hour usage on Mondays (reference day)

Thursday × Rain: $\beta_{4r} = -0.280$, p = 0.014 Rainfall significantly
reduces rush hour usage on Thursdays compared to Mondays

Friday × Rain: $\beta_{5r} = -0.702$, p \< 0.001 Rainfall significantly
reduces rush hour usage on Fridays compared to Mondays

Wednesday × Rain: $\beta_{3r} = 0.010$, p = 0.912

Saturday × Rain: $\beta_{6r} = -0.267$, p = 0.070 (marginally
significant)

Sunday × Rain: $\beta_{7r} = -0.112$, p = 0.407

### Odds Ratio Interpretations:

Tuesday effect: $\exp(0.197) = 1.218$ → 21.8% higher odds of rush hour
departure compared to Monday Friday effect: $\exp(-0.139) = 0.870$ →
13.0% lower odds of rush hour departure compared to Monday Rain effect
on Thursday: $\exp(-0.280) = 0.756$ → 24.4% reduction in odds due to
rain on Thursdays Rain effect on Friday: $\exp(-0.702) = 0.495$ → 50.5%
reduction in odds due to rain on Fridays

## Model Validation

```{r}
# Model Diagnostics with Plots
cat("MODEL DIAGNOSTICS:\n")
cat("• Model converged:", model_rush$converged, "\n")
cat("• Number of iterations:", model_rush$iter, "\n")
cat("• Residual deviance:", round(model_rush$deviance, 2), "\n")
cat("• Null deviance:", round(model_rush$null.deviance, 2), "\n")
cat("• AIC:", round(AIC(model_rush), 2), "\n")
cat("• Dispersion parameter:", round(summary(model_rush)$dispersion, 3), "\n")

# Check for complete separation
coefficients <- coef(model_rush)
coefficients_clean <- coefficients[!is.na(coefficients)]

if(length(coefficients_clean) > 0) {
  if(any(abs(coefficients_clean) > 10)) {
    cat("• Separation check: WARNING - Large coefficients detected\n")
  } else {
    cat("• Separation check: No evidence of complete separation\n")
  }
}

# Check residual deviance for overdispersion
dispersion_ratio <- model_rush$deviance / model_rush$df.residual
cat("• Dispersion ratio:", round(dispersion_ratio, 3), "\n")
if(dispersion_ratio > 1.5) {
  cat("• Overdispersion: WARNING - Potential overdispersion detected\n")
} else {
  cat("• Overdispersion: No significant evidence\n")
}

# Diagnostic Plots
cat("\nGENERATING DIAGNOSTIC PLOTS...\n")

# Set up plotting area
par(mfrow = c(2, 2), mar = c(4, 4, 2, 2))

# 1. Residuals vs Fitted
fitted_values <- fitted(model_rush)
pearson_residuals <- residuals(model_rush, type = "pearson")

plot(fitted_values, pearson_residuals,
     main = "Residuals vs Fitted",
     xlab = "Fitted Values", ylab = "Pearson Residuals",
     pch = 20, col = rgb(0.2, 0.2, 0.8, 0.6))
abline(h = 0, col = "red", lty = 2)
lines(lowess(fitted_values, pearson_residuals), col = "blue", lwd = 2)

# 2. Q-Q Plot of Residuals
qqnorm(pearson_residuals, main = "Q-Q Plot of Residuals",
       pch = 20, col = rgb(0.2, 0.2, 0.8, 0.6))
qqline(pearson_residuals, col = "red", lwd = 2)

# 3. Cook's Distance for Influential Points
cooks_d <- cooks.distance(model_rush)
plot(cooks_d, type = "h",
     main = "Cook's Distance",
     ylab = "Cook's Distance", xlab = "Observation Index")
abline(h = 4/length(cooks_d), col = "red", lty = 2)  # Common threshold
text(x = which.max(cooks_d), y = max(cooks_d),
     labels = "Most influential", pos = 3, cex = 0.8)

# 4. Leverage vs Residuals
leverage <- hatvalues(model_rush)
plot(leverage, pearson_residuals,
     main = "Leverage vs Residuals",
     xlab = "Leverage", ylab = "Pearson Residuals",
     pch = 20, col = rgb(0.2, 0.2, 0.8, 0.6))
abline(h = 0, col = "red", lty = 2)

# Reset plotting parameters
par(mfrow = c(1, 1))

# Additional diagnostic information
cat("\nADDITIONAL DIAGNOSTIC INFORMATION:\n")
cat("• Maximum Cook's Distance:", round(max(cooks_d), 4), "\n")
cat("• Number of influential points (Cook's D > 4/n):", 
    sum(cooks_d > 4/length(cooks_d)), "\n")
cat("• Maximum leverage:", round(max(leverage), 4), "\n")
cat("• Average leverage:", round(mean(leverage), 4), "\n")

# Check for patterns in residuals by day and rain
cat("\nRESIDUAL PATTERNS BY DAY AND RAIN:\n")
residuals_by_group <- bixi_data %>%
  mutate(
    fitted = fitted_values,
    residuals = pearson_residuals
  ) %>%
  group_by(jj, prec_ind) %>%
  summarise(
    mean_residual = mean(residuals),
    sd_residual = sd(residuals),
    n = n(),
    .groups = 'drop'
  )

print(residuals_by_group)

# Final diagnostic assessment
cat("\nOVERALL MODEL DIAGNOSTIC ASSESSMENT:\n")
if(dispersion_ratio < 1.5 && 
   max(cooks_d) < 0.5 && 
   max(leverage) < 2*mean(leverage) &&
   all(abs(residuals_by_group$mean_residual) < 0.5)) {
  cat("✓ Model diagnostics are generally acceptable\n")
  cat("✓ No major violations of model assumptions detected\n")
} else {
  cat("⚠ Some potential issues detected - consider model refinements\n")
}
```

```{r}
#double check overdispersion
dispersion_checks <- function(m){
  phi_P <- sum(residuals(m, type="pearson")^2)  / df.residual(m)
  phi_D <- deviance(m) / df.residual(m)
  cat("Pearson ϕ:", round(phi_P,3), " | Deviance ϕ:", round(phi_D,3), "\n",
      "Use Pearson ϕ for quasi-binomial/robust SE adjustment.\n")
  invisible(c(pearson = phi_P, deviance = phi_D))
}
dispersion_checks(model_rush)

```

```{r}
# Refit with quasi-binomial
model_rush_q <- glm(
  cbind(n_rush, n_non_rush) ~ jj * prec_ind,
  data = bixi_data, 
  family = quasibinomial(link = "logit")
)


```

```{r}
out.bin_m2   <- summary(model_rush)$coefficients
out.quasi_m2 <- summary(model_rush_q)$coefficients

compare <- cbind(
  Binomial_Est  = out.bin_m2[,1],
  Binomial_SE   = out.bin_m2[,2],
  QuasiBin_Est  = out.quasi_m2[,1],
  QuasiBin_SE   = out.quasi_m2[,2],
  SE_ratio      = out.quasi_m2[,2] / out.bin_m2[,2]
)
compare
```

### Interpretation

The first two columns show the estimated coefficients (β̂) and standard
errors from the **Binomial** model, while columns 3–4 present the same
results from the **Quasi-Binomial** model. The coefficient estimates are
identical, as both models share the same mean structure. The
quasi-binomial standard errors are inflated by a constant factor
of **1.4877**, which equals √φ̂ ≈ √2.21, confirming that the
quasi-binomial model correctly adjusts for overdispersion while
preserving the same fitted values.

```{r}
# extract all R code from an .Rmd file
knitr::purl("bixi_project_part2.Rmd", output = "bixi_project_part2_code.R")

```
